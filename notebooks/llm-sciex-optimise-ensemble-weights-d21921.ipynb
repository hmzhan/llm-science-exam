{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Science Exam Optimise Ensemble Weights \n\nIn this competition, when looking for the high-scoring notebooks, those that are ensembles with multiple models stand out. In fact, it is known empirically that ensembles are very powerful in NLP competition.\n\n[The voting ensemble was introduced](https://www.kaggle.com/code/radek1/an-introduction-to-voting-ensemble) by [radek1](https://www.kaggle.com/radek1) and many notes have been published on this basis.\n\nOn the other hand, ensembles with predicted probabilities appear to be less used.\n\nThis notebook introduces ensembles using probabilities and shows how to optimise model weights with **scipy.optimize**.\n\nNormally, OOF(out of fold) predictions are used to optimise model weights, But The training data used looks mixed and most of the weight is for single models. Therefore, I'll use an evaluation dataset that appears not to have been used for training. the dataset named [MMLU-Dataset](https://www.kaggle.com/datasets/peiyuanliu2001/mmlu-dataset) shared by [Peiyuan Liu](https://www.kaggle.com/peiyuanliu2001). [See his discussion for details.](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/433168) Please note that this dataset contains more than just STEM questions, so it may not be suitable as an evaluation dataset.\n\nedit: Somehow unable to submitted due to the MMLU dataset, so I've created a separate dataset.\n\nedit: [Chris Deotte](https://www.kaggle.com/cdeotte) once again published an [amazing dataset](https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2) and notebooks. his [training code is here](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1) and [inference code is here](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-2). This version also uses his trained weights.\n\n### References, see also them\n\nWeight optimization related \n\n* [Optimise Blending Weights with Bonus :0](https://www.kaggle.com/code/gogo827jz/optimise-blending-weights-with-bonus-0/notebook) by [Yirun Zhang](https://www.kaggle.com/gogo827jz)\n\nOpenBook and its tuning related(Too many, so just partial only)\n\n* [OpenBook DeBERTaV3-Large Baseline (Single Model)](https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model) by [Anil Ozturk](https://www.kaggle.com/nlztrk)\n\n* [[0.807] Sharing my trained-with-context model](https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model/notebook) by [MGÃ¶ksu](https://www.kaggle.com/mgoksu)\n\nTrainning and inferring OpenBook Dataset with context\n\n* [How To Train Open Book Model - Part 1](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-1) by [Chris Deotte](https://www.kaggle.com/cdeotte)\n\n* [How To Train Open Book Model - Part 2](https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model-part-2) by [Chris Deotte](https://www.kaggle.com/cdeotte)\n\nVoting ensemble (Too many, so just the original)\n\n* [The voting ensemble was introduced](https://www.kaggle.com/code/radek1/an-introduction-to-voting-ensemble) by [radek1](https://www.kaggle.com/radek1)\n\n### My other Notebooks\n\nIn this competition\n\n* [Incorporate MAP@k metrics into HF Trainer](https://www.kaggle.com/code/itsuki9180/incorporate-map-k-metrics-into-hf-trainer)\n\n* [Introducing Adversarial Weight Perturbation (AWP)](https://www.kaggle.com/code/itsuki9180/introducing-adversarial-weight-perturbation-awp)\n\n* [Adversarial Weight Perturbation (AWP) Inference](https://www.kaggle.com/code/itsuki9180/adversarial-weight-perturbation-awp-inference)\n\n* [Using DeepSpeed with HFðŸ¤— Trainer](https://www.kaggle.com/code/itsuki9180/using-deepspeed-with-hf-trainer)\n\nWeight optimization related (almost same as Yirun Zhangs')\n\n* [G2Net_oof_weight_optimizer](https://www.kaggle.com/code/itsuki9180/g2net-oof-weight-optimizer)","metadata":{}},{"cell_type":"markdown","source":"# How To Train Model for Open Book Q&A Technique - Part 2\nThe notebook you are reading is a fork of Mgoksu's great notebook [here][1]. Mgoksu (@mgoksu) demonstrated how to achieve top public LB=0.807 using Open Book technique. The Open Book method was first presented by JJ (@jjinho) [here][2], then Quangteo (@quangbk) improved RAM usage [here][3], and Anil (@nlztrk) combined with Q&A [here][4]. Radek (@radek1) demonstrated the strength of Q&A [here][5].\n\nIn my previous notebook [here][6] (i.e. Part 1), we demonstrated how to train a model for Open Book. The model was trained using my 60k Kaggle dataset [here][7]. If you enjoy the notebook you are reading, please upvote the dataset too. Thanks!\n\nIn this notebook, we will load the trained model output from my previous notebook. We will infer this model after running the code from Mgoksu's public notebook to use Open Book to seach Wikipedia for context. For each test sample in the hidden dataset, we will append Wikipedia context. Then our trained model will infer the multiple choice answer (using both question and appended Wikipedia context). When predicting the answer, this notebook uses a 50% 50% ensemble of the new Q&A model we trained ensembled with Mgoksu's original model. Here is a diagram showing the Open Book method:\n\n![](https://miro.medium.com/v2/resize:fit:800/format:webp/1*bTGY3fKIgNefQxNsOYpnBw.png)\n\n(image source [here][8])\n\n[1]: https://www.kaggle.com/code/mgoksu/0-807-sharing-my-trained-with-context-model\n[2]: https://www.kaggle.com/code/jjinho/open-book-llm-science-exam\n[3]: https://www.kaggle.com/code/quangbk/open-book-llm-science-exam-reduced-ram-usage\n[4]: https://www.kaggle.com/code/nlztrk/openbook-debertav3-large-baseline-single-model\n[5]: https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training\n[6]: https://www.kaggle.com/code/cdeotte/how-to-train-open-book-model\n[7]: https://www.kaggle.com/datasets/cdeotte/60k-data-with-context-v2\n[8]: https://blog.gopenai.com/enrich-llms-with-retrieval-augmented-generation-rag-17b82a96b6f0","metadata":{}},{"cell_type":"code","source":"# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:53:42.09112Z","iopub.execute_input":"2023-09-13T03:53:42.092251Z","iopub.status.idle":"2023-09-13T03:55:45.864499Z","shell.execute_reply.started":"2023-09-13T03:53:42.09221Z","shell.execute_reply":"2023-09-13T03:55:45.86338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, time\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nfrom dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom torch.utils.data import DataLoader\n\nfrom scipy.special import softmax","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:45.867601Z","iopub.execute_input":"2023-09-13T03:55:45.868359Z","iopub.status.idle":"2023-09-13T03:55:59.356977Z","shell.execute_reply.started":"2023-09-13T03:55:45.868328Z","shell.execute_reply":"2023-09-13T03:55:59.356049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 32\n\ntrn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", axis=1)\n\nDEBUG = False\n# DEBUG = False if len(trn)!=200 else True # If you want to save GPU Quota, check off this comment-out. But cannot get accurate weight on saving notebook\nFILTER_LEN = 1 if DEBUG else 10\nIND_SEARCH = 1 if DEBUG else 7\nNUM_SENTENCES_INCLUDE = 1 if DEBUG else 22\nCONTEXT_LEN = 1000 if DEBUG else 2300\nVAL_SIZE = 200 if DEBUG else 1500\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:59.358187Z","iopub.execute_input":"2023-09-13T03:55:59.358504Z","iopub.status.idle":"2023-09-13T03:55:59.400246Z","shell.execute_reply.started":"2023-09-13T03:55:59.358473Z","shell.execute_reply":"2023-09-13T03:55:59.399344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = FILTER_LEN,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = FILTER_LEN,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:59.404012Z","iopub.execute_input":"2023-09-13T03:55:59.404287Z","iopub.status.idle":"2023-09-13T03:55:59.417246Z","shell.execute_reply.started":"2023-09-13T03:55:59.404263Z","shell.execute_reply":"2023-09-13T03:55:59.416111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", axis=1)\ntrn.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:59.41854Z","iopub.execute_input":"2023-09-13T03:55:59.420264Z","iopub.status.idle":"2023-09-13T03:55:59.448955Z","shell.execute_reply.started":"2023-09-13T03:55:59.420239Z","shell.execute_reply":"2023-09-13T03:55:59.447966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = pd.read_csv('/kaggle/input/mmlu-dataset-valid-only/valid_mmlu_1526_ind0.csv',index_col=0)[:VAL_SIZE]\n\nval['E'] = '' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\nval = val.replace(np.NaN, '')\n\nval['A'] = val['A'].map(str)\nval['B'] = val['B'].map(str)\nval['C'] = val['C'].map(str)\nval['D'] = val['D'].map(str)\nval['E'] = val['E'].map(str)\n\nval.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:59.450189Z","iopub.execute_input":"2023-09-13T03:55:59.450622Z","iopub.status.idle":"2023-09-13T03:55:59.506527Z","shell.execute_reply.started":"2023-09-13T03:55:59.450588Z","shell.execute_reply":"2023-09-13T03:55:59.505633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(SIM_MODEL, device='cuda')\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:55:59.508144Z","iopub.execute_input":"2023-09-13T03:55:59.508506Z","iopub.status.idle":"2023-09-13T03:56:00.821522Z","shell.execute_reply.started":"2023-09-13T03:55:59.508474Z","shell.execute_reply":"2023-09-13T03:56:00.820325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:56:00.822861Z","iopub.execute_input":"2023-09-13T03:56:00.823207Z","iopub.status.idle":"2023-09-13T03:57:23.582216Z","shell.execute_reply.started":"2023-09-13T03:56:00.823175Z","shell.execute_reply":"2023-09-13T03:57:23.581042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n\nprompt_embeddings_v = model.encode(val.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings_v = prompt_embeddings_v.detach().cpu().numpy()\n\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:57:23.584844Z","iopub.execute_input":"2023-09-13T03:57:23.585215Z","iopub.status.idle":"2023-09-13T03:57:30.819833Z","shell.execute_reply.started":"2023-09-13T03:57:23.585179Z","shell.execute_reply":"2023-09-13T03:57:30.818863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the top IND_SEARCH pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, IND_SEARCH)\n\nsearch_score_v, search_index_v = sentence_index.search(prompt_embeddings_v, IND_SEARCH)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:57:30.825035Z","iopub.execute_input":"2023-09-13T03:57:30.825333Z","iopub.status.idle":"2023-09-13T03:58:13.181228Z","shell.execute_reply.started":"2023-09-13T03:57:30.825307Z","shell.execute_reply":"2023-09-13T03:58:13.180426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings,  prompt_embeddings_v\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:58:13.18503Z","iopub.execute_input":"2023-09-13T03:58:13.187148Z","iopub.status.idle":"2023-09-13T03:58:14.01348Z","shell.execute_reply.started":"2023-09-13T03:58:13.187118Z","shell.execute_reply":"2023-09-13T03:58:14.01249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Sentences from the Relevant Titles","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\", columns=['id', 'file'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:58:14.014772Z","iopub.execute_input":"2023-09-13T03:58:14.015192Z","iopub.status.idle":"2023-09-13T03:58:18.451909Z","shell.execute_reply.started":"2023-09-13T03:58:14.015159Z","shell.execute_reply":"2023-09-13T03:58:18.450892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\nwikipedia_file_data_v = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score_v, search_index_v)), total=len(search_score_v)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data_v.append(_df)\nwikipedia_file_data_v = pd.concat(wikipedia_file_data_v).reset_index(drop=True)\nwikipedia_file_data_v = wikipedia_file_data_v[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n\ndel df\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:58:18.453Z","iopub.execute_input":"2023-09-13T03:58:18.458602Z","iopub.status.idle":"2023-09-13T03:58:19.581298Z","shell.execute_reply.started":"2023-09-13T03:58:18.458563Z","shell.execute_reply":"2023-09-13T03:58:19.580136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\nwiki_text_data_v = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n\nfor file in tqdm(wikipedia_file_data_v.file.unique(), total=len(wikipedia_file_data_v.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data_v[wikipedia_file_data_v['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data_v.append(_df_temp)\nwiki_text_data_v = pd.concat(wiki_text_data_v).drop_duplicates().reset_index(drop=True)\n\n\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T03:58:19.583112Z","iopub.execute_input":"2023-09-13T03:58:19.583478Z","iopub.status.idle":"2023-09-13T04:05:49.921866Z","shell.execute_reply.started":"2023-09-13T03:58:19.583445Z","shell.execute_reply":"2023-09-13T04:05:49.920884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)\n\nprocessed_wiki_text_data_v = process_documents(wiki_text_data_v.text.values, wiki_text_data_v.id.values)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:05:49.923285Z","iopub.execute_input":"2023-09-13T04:05:49.923719Z","iopub.status.idle":"2023-09-13T04:05:53.392552Z","shell.execute_reply.started":"2023-09-13T04:05:49.923683Z","shell.execute_reply":"2023-09-13T04:05:53.391432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()\n\nwiki_data_embeddings_v = model.encode(processed_wiki_text_data_v.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings_v = wiki_data_embeddings_v.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:05:53.39419Z","iopub.execute_input":"2023-09-13T04:05:53.394552Z","iopub.status.idle":"2023-09-13T04:06:06.788477Z","shell.execute_reply.started":"2023-09-13T04:05:53.394518Z","shell.execute_reply":"2023-09-13T04:06:06.787305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:06.789893Z","iopub.execute_input":"2023-09-13T04:06:06.790324Z","iopub.status.idle":"2023-09-13T04:06:07.064031Z","shell.execute_reply.started":"2023-09-13T04:06:06.79029Z","shell.execute_reply":"2023-09-13T04:06:07.063017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:07.065485Z","iopub.execute_input":"2023-09-13T04:06:07.066113Z","iopub.status.idle":"2023-09-13T04:06:07.083257Z","shell.execute_reply.started":"2023-09-13T04:06:07.066076Z","shell.execute_reply":"2023-09-13T04:06:07.082246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val['A'] = val['A'].map(str)\nval['B'] = val['B'].map(str)\nval['C'] = val['C'].map(str)\nval['D'] = val['D'].map(str)\nval['E'] = val['E'].map(str)\n\nval['answer_all'] = val.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\nval['prompt_answer_stem'] = val['prompt'] + \" \" + val['answer_all']","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:07.084957Z","iopub.execute_input":"2023-09-13T04:06:07.085316Z","iopub.status.idle":"2023-09-13T04:06:07.104237Z","shell.execute_reply.started":"2023-09-13T04:06:07.085284Z","shell.execute_reply":"2023-09-13T04:06:07.103051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings = question_embeddings.detach().cpu().numpy()\n\nquestion_embeddings_v = model.encode(val.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings_v = question_embeddings_v.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:07.105875Z","iopub.execute_input":"2023-09-13T04:06:07.106255Z","iopub.status.idle":"2023-09-13T04:06:07.648053Z","shell.execute_reply.started":"2023-09-13T04:06:07.106223Z","shell.execute_reply":"2023-09-13T04:06:07.647065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Matching Prompt-Sentence Pairs","metadata":{}},{"cell_type":"code","source":"contexts = []\ncontexts_v = []\n\nfor r in tqdm(trn.itertuples(), total=len(trn)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts.append(context)\n    \n    \nfor r in tqdm(val.itertuples(), total=len(val)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data_v[processed_wiki_text_data_v['document_id'].isin(wikipedia_file_data_v[wikipedia_file_data_v['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings_v.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings_v[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings_v, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data_v.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts_v.append(context)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:07.649841Z","iopub.execute_input":"2023-09-13T04:06:07.650503Z","iopub.status.idle":"2023-09-13T04:06:08.729815Z","shell.execute_reply.started":"2023-09-13T04:06:07.650467Z","shell.execute_reply":"2023-09-13T04:06:08.728886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts\nval['context'] = contexts_v","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:08.73255Z","iopub.execute_input":"2023-09-13T04:06:08.732848Z","iopub.status.idle":"2023-09-13T04:06:08.741237Z","shell.execute_reply.started":"2023-09-13T04:06:08.732809Z","shell.execute_reply":"2023-09-13T04:06:08.740184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)\nval[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\", \"answer\"]].to_csv(\"./val_context.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:08.743474Z","iopub.execute_input":"2023-09-13T04:06:08.744706Z","iopub.status.idle":"2023-09-13T04:06:08.772718Z","shell.execute_reply.started":"2023-09-13T04:06:08.744668Z","shell.execute_reply":"2023-09-13T04:06:08.771863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"test_context.csv\")\ntest_df.index = list(range(len(test_df)))\ntest_df['id'] = list(range(len(test_df)))\ntest_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  test_df[\"prompt\"]\ntest_df['answer'] = 'A'\n\nval_df = pd.read_csv(\"val_context.csv\")\nval_df.index = list(range(len(val_df)))\nval_df['id'] = list(range(len(val_df)))\nval_df[\"prompt\"] = val_df[\"context\"].apply(lambda x: x[:CONTEXT_LEN]) + \" #### \" +  val_df[\"prompt\"]\nval_df = val_df.replace(np.NaN, '')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:08.774103Z","iopub.execute_input":"2023-09-13T04:06:08.774498Z","iopub.status.idle":"2023-09-13T04:06:08.797901Z","shell.execute_reply.started":"2023-09-13T04:06:08.774474Z","shell.execute_reply":"2023-09-13T04:06:08.797008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-science-run-context-2\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:08.799299Z","iopub.execute_input":"2023-09-13T04:06:08.799741Z","iopub.status.idle":"2023-09-13T04:06:27.561942Z","shell.execute_reply.started":"2023-09-13T04:06:08.799706Z","shell.execute_reply":"2023-09-13T04:06:27.5609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n  \n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    \n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation='only_first')\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:27.56326Z","iopub.execute_input":"2023-09-13T04:06:27.563651Z","iopub.status.idle":"2023-09-13T04:06:27.571432Z","shell.execute_reply.started":"2023-09-13T04:06:27.563616Z","shell.execute_reply":"2023-09-13T04:06:27.570229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:27.573134Z","iopub.execute_input":"2023-09-13T04:06:27.573814Z","iopub.status.idle":"2023-09-13T04:06:27.585414Z","shell.execute_reply.started":"2023-09-13T04:06:27.573779Z","shell.execute_reply":"2023-09-13T04:06:27.584422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)\n\ntokenized_val_dataset = Dataset.from_pandas(val_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_val_dataset = tokenized_val_dataset.remove_columns([\"__index_level_0__\"])\n\nval_dataloader = DataLoader(tokenized_val_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:27.59832Z","iopub.execute_input":"2023-09-13T04:06:27.59861Z","iopub.status.idle":"2023-09-13T04:06:28.580032Z","shell.execute_reply.started":"2023-09-13T04:06:27.598584Z","shell.execute_reply":"2023-09-13T04:06:28.576225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = []\nval_predictions = []\n\nfor batch in tqdm(test_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictions.append(outputs.logits.cpu().detach())\n    \nfor batch in tqdm(val_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    val_predictions.append(outputs.logits.cpu().detach())\n\ntest_predictions = torch.cat(test_predictions)\nval_predictions = torch.cat(val_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:06:28.581583Z","iopub.execute_input":"2023-09-13T04:06:28.58196Z","iopub.status.idle":"2023-09-13T04:07:03.102863Z","shell.execute_reply.started":"2023-09-13T04:06:28.581926Z","shell.execute_reply":"2023-09-13T04:07:03.101894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = softmax(test_predictions, axis=1).numpy()\nval_predictions = softmax(val_predictions, axis=1).numpy().astype(np.float16)\n\n\nprob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\ndf_prob = pd.DataFrame(zip(*val_predictions.T), index=val_df.index, columns=prob_lables)\ndf_prob.to_csv('openbook_val.csv')\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:03.104466Z","iopub.execute_input":"2023-09-13T04:07:03.105084Z","iopub.status.idle":"2023-09-13T04:07:03.141843Z","shell.execute_reply.started":"2023-09-13T04:07:03.105047Z","shell.execute_reply":"2023-09-13T04:07:03.140772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ob_preds = test_predictions\nob_preds_v = val_predictions\ndel test_predictions, val_predictions","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:03.143339Z","iopub.execute_input":"2023-09-13T04:07:03.143679Z","iopub.status.idle":"2023-09-13T04:07:03.148592Z","shell.execute_reply.started":"2023-09-13T04:07:03.143645Z","shell.execute_reply":"2023-09-13T04:07:03.147491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/how-to-train-open-book-model-part-1/model_v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:03.150325Z","iopub.execute_input":"2023-09-13T04:07:03.150725Z","iopub.status.idle":"2023-09-13T04:07:20.860482Z","shell.execute_reply.started":"2023-09-13T04:07:03.150687Z","shell.execute_reply":"2023-09-13T04:07:20.859391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictionsc = []\nval_predictionsc = []\n\nfor batch in tqdm(test_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictionsc.append(outputs.logits.cpu().detach())\n    \nfor batch in tqdm(val_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    val_predictionsc.append(outputs.logits.cpu().detach())\n\ntest_predictionsc = torch.cat(test_predictionsc)\nval_predictionsc = torch.cat(val_predictionsc)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:20.861994Z","iopub.execute_input":"2023-09-13T04:07:20.862425Z","iopub.status.idle":"2023-09-13T04:07:55.528953Z","shell.execute_reply.started":"2023-09-13T04:07:20.862389Z","shell.execute_reply":"2023-09-13T04:07:55.527891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictionsc = softmax(test_predictionsc, axis=1).numpy()\nval_predictionsc = softmax(val_predictionsc, axis=1).numpy().astype(np.float16)\n\nprob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\ndf_prob = pd.DataFrame(zip(*val_predictionsc.T), index=val_df.index, columns=prob_lables)\ndf_prob.to_csv('chris_val.csv')\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:55.530592Z","iopub.execute_input":"2023-09-13T04:07:55.530967Z","iopub.status.idle":"2023-09-13T04:07:55.554679Z","shell.execute_reply.started":"2023-09-13T04:07:55.530933Z","shell.execute_reply":"2023-09-13T04:07:55.553725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:55.555868Z","iopub.execute_input":"2023-09-13T04:07:55.556619Z","iopub.status.idle":"2023-09-13T04:07:55.851988Z","shell.execute_reply.started":"2023-09-13T04:07:55.556584Z","shell.execute_reply":"2023-09-13T04:07:55.850861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/using-deepspeed-with-hf-trainer/checkpoints_1\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:07:55.853792Z","iopub.execute_input":"2023-09-13T04:07:55.854188Z","iopub.status.idle":"2023-09-13T04:08:06.673396Z","shell.execute_reply.started":"2023-09-13T04:07:55.854152Z","shell.execute_reply":"2023-09-13T04:08:06.672237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictionsi = []\nval_predictionsi = []\n\nfor batch in tqdm(test_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictionsi.append(outputs.logits.cpu().detach())\n    \nfor batch in tqdm(val_dataloader):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    val_predictionsi.append(outputs.logits.cpu().detach())\n\ntest_predictionsi = torch.cat(test_predictionsi)\nval_predictionsi = torch.cat(val_predictionsi)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:06.67486Z","iopub.execute_input":"2023-09-13T04:08:06.675278Z","iopub.status.idle":"2023-09-13T04:08:41.077387Z","shell.execute_reply.started":"2023-09-13T04:08:06.675244Z","shell.execute_reply":"2023-09-13T04:08:41.076431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictionsi = softmax(test_predictionsi, axis=1).numpy()\nval_predictionsi = softmax(val_predictionsi, axis=1).numpy().astype(np.float16)\n\nprob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\ndf_prob = pd.DataFrame(zip(*val_predictionsi.T), index=val_df.index, columns=prob_lables)\ndf_prob.to_csv('itk_ob_val.csv')\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:41.079173Z","iopub.execute_input":"2023-09-13T04:08:41.079861Z","iopub.status.idle":"2023-09-13T04:08:41.104788Z","shell.execute_reply.started":"2023-09-13T04:08:41.079804Z","shell.execute_reply":"2023-09-13T04:08:41.10379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In order to increase diversity, we also use some weights that do not use openbook.","metadata":{}},{"cell_type":"code","source":"from typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\nfrom torch.utils.data import DataLoader\ndeberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'\nimport os\nos.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:41.106145Z","iopub.execute_input":"2023-09-13T04:08:41.106585Z","iopub.status.idle":"2023-09-13T04:08:41.113359Z","shell.execute_reply.started":"2023-09-13T04:08:41.10654Z","shell.execute_reply":"2023-09-13T04:08:41.112227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [example['prompt']] * 5\n    second_sentences = [example[option] for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:41.114892Z","iopub.execute_input":"2023-09-13T04:08:41.115554Z","iopub.status.idle":"2023-09-13T04:08:41.129484Z","shell.execute_reply.started":"2023-09-13T04:08:41.115521Z","shell.execute_reply":"2023-09-13T04:08:41.128714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n\ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df['answer'] = 'A' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\n\nval_df = pd.read_csv('/kaggle/input/mmlu-dataset-valid-only/valid_mmlu_1526_ind0.csv',index_col=0)[:VAL_SIZE]\n\nval_df['E'] = '' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\nval_df = val_df.replace(np.NaN, '')\n\nval_df['A'] = val_df['A'].map(str)\nval_df['B'] = val_df['B'].map(str)\nval_df['C'] = val_df['C'].map(str)\nval_df['D'] = val_df['D'].map(str)\nval_df['E'] = val_df['E'].map(str)\n\nval_df.reset_index(inplace=True, drop=True)\n\ntokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, 1, shuffle=False, collate_fn=data_collator, num_workers=0, pin_memory=True,)\n\n\ntokenized_val_dataset = Dataset.from_pandas(val_df).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\nval_dataloader = DataLoader(tokenized_val_dataset, 1, shuffle=False, collate_fn=data_collator, num_workers=0, pin_memory=True,)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:41.130927Z","iopub.execute_input":"2023-09-13T04:08:41.131616Z","iopub.status.idle":"2023-09-13T04:08:43.139353Z","shell.execute_reply.started":"2023-09-13T04:08:41.131558Z","shell.execute_reply":"2023-09-13T04:08:43.138256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(f'/kaggle/input/2023kagglellm-deberta-v3-large-model1').cuda()\nmodel.eval()\n\npreds = []\npreds_v = []\n\nfor batch in tqdm(test_dataloader, total=len(test_dataloader)):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    preds.append(outputs.logits.cpu().detach())\n    \nfor batch in tqdm(val_dataloader, total=len(val_dataloader)):\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    preds_v.append(outputs.logits.cpu().detach())\n\nhyc_preds = torch.cat(preds)\nhyc_preds_v = torch.cat(preds_v)\n\ndel model\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:08:43.140782Z","iopub.execute_input":"2023-09-13T04:08:43.141234Z","iopub.status.idle":"2023-09-13T04:09:25.252284Z","shell.execute_reply.started":"2023-09-13T04:08:43.141198Z","shell.execute_reply":"2023-09-13T04:09:25.251264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyc_preds = softmax(hyc_preds, axis=1).numpy()\nhyc_preds_v = softmax(hyc_preds_v, axis=1).numpy().astype(np.float16)\nprob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\ndf_prob = pd.DataFrame(zip(*hyc_preds_v.T), index=val_df.index, columns=prob_lables)\ndf_prob.to_csv('hyc_val.csv')\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.253872Z","iopub.execute_input":"2023-09-13T04:09:25.254238Z","iopub.status.idle":"2023-09-13T04:09:25.279855Z","shell.execute_reply.started":"2023-09-13T04:09:25.254205Z","shell.execute_reply":"2023-09-13T04:09:25.278867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.281425Z","iopub.execute_input":"2023-09-13T04:09:25.281781Z","iopub.status.idle":"2023-09-13T04:09:25.652998Z","shell.execute_reply.started":"2023-09-13T04:09:25.281749Z","shell.execute_reply":"2023-09-13T04:09:25.651805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob\nfrom typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer, AutoConfig\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.654597Z","iopub.execute_input":"2023-09-13T04:09:25.655023Z","iopub.status.idle":"2023-09-13T04:09:25.663173Z","shell.execute_reply.started":"2023-09-13T04:09:25.654989Z","shell.execute_reply":"2023-09-13T04:09:25.662189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_DIR = '/kaggle/input/llm-kaggle-awp'\nCONF_PATH = MODEL_DIR + '/deberta-v3-large_config.pth'\nMODEL_PATH = MODEL_DIR + '/best_model_public.pt'","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.664585Z","iopub.execute_input":"2023-09-13T04:09:25.665282Z","iopub.status.idle":"2023-09-13T04:09:25.672049Z","shell.execute_reply.started":"2023-09-13T04:09:25.665249Z","shell.execute_reply":"2023-09-13T04:09:25.670514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.673286Z","iopub.execute_input":"2023-09-13T04:09:25.674004Z","iopub.status.idle":"2023-09-13T04:09:25.683258Z","shell.execute_reply.started":"2023-09-13T04:09:25.673969Z","shell.execute_reply":"2023-09-13T04:09:25.681758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df['answer'] = 'A' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\ntest_df = test_df.replace(np.NaN, '')\n\nval_df = pd.read_csv('/kaggle/input/mmlu-dataset-valid-only/valid_mmlu_1526_ind0.csv',index_col=0)[:VAL_SIZE]\n\nval_df['E'] = '' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\nval_df = val_df.replace(np.NaN, '')\n\nval_df['A'] = val_df['A'].map(str)\nval_df['B'] = val_df['B'].map(str)\nval_df['C'] = val_df['C'].map(str)\nval_df['D'] = val_df['D'].map(str)\nval_df['E'] = val_df['E'].map(str)\n\nval_df.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.684732Z","iopub.execute_input":"2023-09-13T04:09:25.685107Z","iopub.status.idle":"2023-09-13T04:09:25.719361Z","shell.execute_reply.started":"2023-09-13T04:09:25.685075Z","shell.execute_reply":"2023-09-13T04:09:25.718416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR+'/tokenizer')\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:25.720631Z","iopub.execute_input":"2023-09-13T04:09:25.72162Z","iopub.status.idle":"2023-09-13T04:09:26.032749Z","shell.execute_reply.started":"2023-09-13T04:09:25.721588Z","shell.execute_reply":"2023-09-13T04:09:26.031869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LlmseDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.a2i = {alp: idx for idx, alp in enumerate('ABCDE')}\n        self.i2a = {v: k for k,v in self.a2i.items()}\n        self.perm_dict = {0: [1,2,3,4],\n                     1: [2,3,4,0], \n                     2: [3,4,0,1],\n                     3: [4,0,1,2],\n                     4: [0,1,2,3]}\n  \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        example = self.df.iloc[idx]\n        tokenized_example = dict()              \n\n        first_sentence = [example['prompt']] * 5\n        second_sentences = [example[option] for option in 'ABCDE']\n        other_sentences = [[] for i in range(5)]\n\n        for i, p in enumerate(range(5)):\n            value = self.perm_dict[p] \n            for v in value:\n                al = self.i2a[v] \n                second_sentences[i]+= ' ' + example[al]\n\n        tokenized_example = tokenizer(first_sentence, \n                                      second_sentences,\n                                      truncation='only_first')\n        tokenized_example['label'] = option_to_index[example['answer']]\n        return tokenized_example\n            \nval_ds = LlmseDataset(val_df)    \ntest_ds = LlmseDataset(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:26.034154Z","iopub.execute_input":"2023-09-13T04:09:26.034517Z","iopub.status.idle":"2023-09-13T04:09:26.047256Z","shell.execute_reply.started":"2023-09-13T04:09:26.034482Z","shell.execute_reply":"2023-09-13T04:09:26.046282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n\nval_dl = DataLoader(\n    val_ds, \n    batch_size=1, \n    shuffle=False, \n    collate_fn=data_collator,\n    num_workers=0,\n    pin_memory=True,\n    drop_last=False\n)\n\ntest_dl = DataLoader(\n    test_ds, \n    batch_size=1, \n    shuffle=False, \n    collate_fn=data_collator,\n    num_workers=0,\n    pin_memory=True,\n    drop_last=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:26.048621Z","iopub.execute_input":"2023-09-13T04:09:26.049216Z","iopub.status.idle":"2023-09-13T04:09:26.06215Z","shell.execute_reply.started":"2023-09-13T04:09:26.049182Z","shell.execute_reply":"2023-09-13T04:09:26.061062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_conf, *, dropout=0.2, pretrained=True):\n        super().__init__()\n\n        # Transformer\n        #self.config = AutoConfig.from_pretrained(model_conf)\n\n        self.transformer = AutoModelForMultipleChoice.from_config(model_conf)\n\n        #self._init_weights(self.fc, self.config)\n\n    def _init_weights(self, module, config):\n        module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n        if module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        out = self.transformer(input_ids, attention_mask, token_type_ids=token_type_ids)\n        x = out['logits'] \n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:26.063665Z","iopub.execute_input":"2023-09-13T04:09:26.064102Z","iopub.status.idle":"2023-09-13T04:09:26.073592Z","shell.execute_reply.started":"2023-09-13T04:09:26.064051Z","shell.execute_reply":"2023-09-13T04:09:26.072604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = torch.load(CONF_PATH)\nmodel = CustomModel(model_conf=config)\nmodel.load_state_dict(torch.load(MODEL_PATH))\nmodel.to(device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:26.074756Z","iopub.execute_input":"2023-09-13T04:09:26.075165Z","iopub.status.idle":"2023-09-13T04:09:49.935539Z","shell.execute_reply.started":"2023-09-13T04:09:26.075132Z","shell.execute_reply":"2023-09-13T04:09:49.934636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = []\ny_preds_v = []\n\nwith tqdm(test_dl, leave=True) as pbar:\n    with torch.no_grad():\n        for idx, batch in enumerate(pbar):\n            inp_ids = batch['input_ids'].to(device)\n            att_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n\n            y_pred = model(input_ids=inp_ids, \n                           attention_mask=att_mask, \n                           token_type_ids=token_type_ids)\n\n            y_pred = y_pred.to(torch.float)\n\n            y_preds.append(y_pred.cpu())\n            \nwith tqdm(val_dl, leave=True) as pbar:\n    with torch.no_grad():\n        for idx, batch in enumerate(pbar):\n            inp_ids = batch['input_ids'].to(device)\n            att_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n\n            y_pred = model(input_ids=inp_ids, \n                           attention_mask=att_mask, \n                           token_type_ids=token_type_ids)\n\n            y_pred = y_pred.to(torch.float)\n\n            y_preds_v.append(y_pred.cpu())\n            \n        \nitk_preds = torch.cat(y_preds)\nitk_preds_v = torch.cat(y_preds_v)\ndel model, y_preds, y_preds_v\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:09:49.936878Z","iopub.execute_input":"2023-09-13T04:09:49.937301Z","iopub.status.idle":"2023-09-13T04:10:31.599507Z","shell.execute_reply.started":"2023-09-13T04:09:49.937267Z","shell.execute_reply":"2023-09-13T04:10:31.598411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itk_preds = softmax(itk_preds, axis=1).numpy()\nitk_preds_v = softmax(itk_preds_v, axis=1).numpy().astype(np.float16)\nprob_lables = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\ndf_prob = pd.DataFrame(zip(*itk_preds_v.T), index=val_df.index, columns=prob_lables)\ndf_prob.to_csv('itk_awp_val.csv')\ndf_prob","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:31.601209Z","iopub.execute_input":"2023-09-13T04:10:31.601604Z","iopub.status.idle":"2023-09-13T04:10:31.625466Z","shell.execute_reply.started":"2023-09-13T04:10:31.601568Z","shell.execute_reply":"2023-09-13T04:10:31.623875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_prob\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:31.627758Z","iopub.execute_input":"2023-09-13T04:10:31.628478Z","iopub.status.idle":"2023-09-13T04:10:31.924117Z","shell.execute_reply.started":"2023-09-13T04:10:31.628441Z","shell.execute_reply":"2023-09-13T04:10:31.922706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimise model weights","metadata":{}},{"cell_type":"code","source":"from scipy.optimize import minimize, fsolve\nimport datetime\nimport torch.nn.functional as F\nfrom numba import njit","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:31.925485Z","iopub.execute_input":"2023-09-13T04:10:31.925974Z","iopub.status.idle":"2023-09-13T04:10:32.478224Z","shell.execute_reply.started":"2023-09-13T04:10:31.92594Z","shell.execute_reply":"2023-09-13T04:10:32.477281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apk(actual, predicted, k=5):\n    \"\"\"\n    Computes the average precision at k.\n    This function computes the average prescision at k between two lists of\n    items.\n    Parameters\n    ----------\n    actual : list\n             A list of elements that are to be predicted (order doesn't matter)\n    predicted : list\n                A list of predicted elements (order does matter)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The average precision at k over the input lists\n    \"\"\"\n    \n    # requires all elements are unique\n    assert (len(np.unique(predicted)) == len(predicted))\n\n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        # first condition checks whether it is valid prediction\n        # second condition checks if prediction is not repeated\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=5):\n    \n    \"\"\"\n    Computes the mean average precision at k.\n    This function computes the mean average prescision at k between two lists\n    of lists of items.\n    Parameters\n    ----------\n    actual : list\n             A list of lists of elements that are to be predicted \n             (order doesn't matter in the lists)\n    predicted : list\n                A list of lists of predicted elements\n                (order matters in the lists)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:32.479521Z","iopub.execute_input":"2023-09-13T04:10:32.479866Z","iopub.status.idle":"2023-09-13T04:10:32.489714Z","shell.execute_reply.started":"2023-09-13T04:10:32.479815Z","shell.execute_reply":"2023-09-13T04:10:32.488752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@njit\ndef grad_func_jit(weights):\n    preds_clip = np.minimum(1 - 1e-15, np.maximum(preds, 1e-15))\n    gradients = np.zeros(preds.shape[0])\n    for i in range(preds.shape[0]):\n        a, b, c = target_values, preds_clip[i], np.zeros((preds.shape[1], preds.shape[2]))\n        a = np.eye(5)[a]\n        for j in range(preds.shape[0]):\n            if j != i:\n                c += weights[j] * preds_clip[j]\n        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n    return gradients","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:32.491128Z","iopub.execute_input":"2023-09-13T04:10:32.491755Z","iopub.status.idle":"2023-09-13T04:10:32.615725Z","shell.execute_reply.started":"2023-09-13T04:10:32.491712Z","shell.execute_reply":"2023-09-13T04:10:32.614831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_mtr(predicted, k=3):\n    y_preds = np.argsort(-predicted, 1)\n    map3 = mapk(target_values.reshape(-1, 1), y_preds.reshape(-1, 5), k=k)\n    return map3\n\n# def calc_loss(predicted):\n#     score = F.cross_entropy(torch.tensor(predicted), torch.tensor(target_values)).numpy()\n#     return score\n\n\ndef log_loss_numpy(y_pred):\n    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    loss = - target_values_one_hot * np.log(y_pred)\n    loss = np.sum(loss, axis=-1)\n    return loss.mean()\n\ndef func_to_optimise(weights):\n    pred_blend = np.tensordot(weights, preds, axes = ((0), (0)))\n    score = log_loss_numpy(pred_blend)\n    return score\n\ndef func_to_map3(weights):\n    pred_blend = np.tensordot(weights, preds, axes = ((0), (0)))\n    score = calc_mtr(pred_blend)\n    return score","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:48.315785Z","iopub.execute_input":"2023-09-13T04:18:48.316171Z","iopub.status.idle":"2023-09-13T04:18:48.323921Z","shell.execute_reply.started":"2023-09-13T04:18:48.316143Z","shell.execute_reply":"2023-09-13T04:18:48.322948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('/kaggle/input/mmlu-dataset-valid-only/valid_mmlu_1526_ind0.csv',index_col=0)[:VAL_SIZE]\n\nval_df['E'] = '' # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\nval_df = val_df.replace(np.NaN, '')\n\nval_df['A'] = val_df['A'].map(str)\nval_df['B'] = val_df['B'].map(str)\nval_df['C'] = val_df['C'].map(str)\nval_df['D'] = val_df['D'].map(str)\nval_df['E'] = val_df['E'].map(str)\n\nval_df.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:48.494185Z","iopub.execute_input":"2023-09-13T04:18:48.494729Z","iopub.status.idle":"2023-09-13T04:18:48.520779Z","shell.execute_reply.started":"2023-09-13T04:18:48.494694Z","shell.execute_reply":"2023-09-13T04:18:48.519855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\ntarget_values = val_df['answer'].map(option_to_index).values\ntarget_values_one_hot = np.eye(5)[target_values]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:48.672938Z","iopub.execute_input":"2023-09-13T04:18:48.675208Z","iopub.status.idle":"2023-09-13T04:18:48.684174Z","shell.execute_reply.started":"2023-09-13T04:18:48.675173Z","shell.execute_reply":"2023-09-13T04:18:48.683308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_dict = {\n    'chris': val_predictionsc,\n    'openbook': ob_preds_v,\n    'itk_ob': val_predictionsi,   \n    'hyc': hyc_preds_v,\n    'itk_awp': itk_preds_v\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:48.882948Z","iopub.execute_input":"2023-09-13T04:18:48.883726Z","iopub.status.idle":"2023-09-13T04:18:48.888774Z","shell.execute_reply.started":"2023-09-13T04:18:48.883689Z","shell.execute_reply":"2023-09-13T04:18:48.887779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.zeros((len(preds_dict), len(val_df), 5))\nfor i in range(preds.shape[0]):\n    preds[i] = list(preds_dict.values())[i]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:49.301662Z","iopub.execute_input":"2023-09-13T04:18:49.302346Z","iopub.status.idle":"2023-09-13T04:18:49.309653Z","shell.execute_reply.started":"2023-09-13T04:18:49.302314Z","shell.execute_reply":"2023-09-13T04:18:49.308511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmap3_scores = {}\nfor n, key in enumerate(preds_dict.keys()):\n    score_val = calc_mtr(preds[n])\n    map3_scores[key] = score_val\n    print(f'{key:40s} CV_map@3:', score_val)\n    \nprint('-' * 60)\n\nloss_scores = {}\nfor n, key in enumerate(preds_dict.keys()):\n    score_val = log_loss_numpy(preds[n])\n    loss_scores[key] = score_val\n    print(f'{key:40s} CV_CELoss:', score_val)\n    \nprint('-' * 60)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:18:49.564178Z","iopub.execute_input":"2023-09-13T04:18:49.564461Z","iopub.status.idle":"2023-09-13T04:18:49.614033Z","shell.execute_reply.started":"2023-09-13T04:18:49.564435Z","shell.execute_reply":"2023-09-13T04:18:49.613132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ln(5) = 1.60943791243 and losses are about 1.5, So the models seem to be making near-random predictions. As I said at the beginning, the validation dataset may not be suitable, but I will continue.","metadata":{}},{"cell_type":"markdown","source":"### Observe correlation\nIt is not the good way to increase the weight of model just because the CV is high. Correlation between models is also an important index in determining weights. In general, we can aim for a high score improvement by ensemble models with good CV and low correlation.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\n\nsubs = np.zeros((len(preds_dict), len(val_df), 5))\n\nfor i, p in enumerate(preds_dict.keys()):\n    print(i,p)\n    subs[i,:,:] = list(preds_dict.values())[i]\n    \ncorr = np.corrcoef(subs.reshape(len(preds_dict), -1))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 12))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, annot=True, fmt=\"g\",\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\nax.set_ylim(corr.shape[0], 0)\nplt.yticks(rotation=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:21.958166Z","iopub.execute_input":"2023-09-13T04:19:21.958528Z","iopub.status.idle":"2023-09-13T04:19:22.45963Z","shell.execute_reply.started":"2023-09-13T04:19:21.958499Z","shell.execute_reply":"2023-09-13T04:19:22.458721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Blending Weights Optimize","metadata":{}},{"cell_type":"markdown","source":"Maximising MAP@3 is very difficult(Is it even possible?). so Minimising CE loss here.","metadata":{}},{"cell_type":"code","source":"tol = 1e-10\ninit_guess = [1 / preds.shape[0]] * preds.shape[0]\nbnds = [(0, 1) for _ in range(preds.shape[0])]\ncons = {'type': 'eq', \n        'fun': lambda x: np.sum(x) - 1, \n        'jac': lambda x: [1] * len(x)}\n\nprint('Inital Blend Loss:', func_to_optimise(init_guess))\nprint('Inital Blend MAP@3:', func_to_map3(init_guess))\nstart_time = time.time()\n\nres_scipy = minimize(fun = func_to_optimise, \n                     x0 = init_guess, \n                     method = 'SLSQP', \n                     tol = tol,\n                     bounds = bnds,\n                     jac = grad_func_jit, \n                     constraints = cons,\n                     options={\"disp\":True,\"maxiter\":1000})\n\nprint(f'[{str(datetime.timedelta(seconds = time.time() - start_time))[2:7]}] Optimised Blend Loss:', res_scipy.fun, ', Optimised Blend MAP@3:', func_to_map3(res_scipy.x))\nprint('Optimised Weights:', res_scipy.x)\nprint('-' * 70)\n\nfor n, key in enumerate(preds_dict.keys()):\n    print(f'{key:40s} Optimised Weights:', res_scipy.x[n])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:23.875028Z","iopub.execute_input":"2023-09-13T04:19:23.875432Z","iopub.status.idle":"2023-09-13T04:19:26.324739Z","shell.execute_reply.started":"2023-09-13T04:19:23.875403Z","shell.execute_reply":"2023-09-13T04:19:26.323528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apply weights and make submission","metadata":{}},{"cell_type":"code","source":"ws = [res_scipy.x[i] for i in range(len(preds_dict.keys()))]\nws = ws / np.sum(ws)\nws","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:26.327267Z","iopub.execute_input":"2023-09-13T04:19:26.327756Z","iopub.status.idle":"2023-09-13T04:19:26.335334Z","shell.execute_reply.started":"2023-09-13T04:19:26.327717Z","shell.execute_reply":"2023-09-13T04:19:26.334411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_overall = test_predictionsc * ws[0] + ob_preds * ws[1] + test_predictionsi * ws[2] + hyc_preds * ws[3] + itk_preds * ws[4]\npredictions_overall.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:26.336942Z","iopub.execute_input":"2023-09-13T04:19:26.33762Z","iopub.status.idle":"2023-09-13T04:19:26.348053Z","shell.execute_reply.started":"2023-09-13T04:19:26.337586Z","shell.execute_reply":"2023-09-13T04:19:26.346751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_overall = predictions_overall\npredictions_overall = np.argsort(-predictions_overall)[:,:3]\npredictions_overall[:5]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:26.351194Z","iopub.execute_input":"2023-09-13T04:19:26.351615Z","iopub.status.idle":"2023-09-13T04:19:26.358146Z","shell.execute_reply.started":"2023-09-13T04:19:26.351583Z","shell.execute_reply":"2023-09-13T04:19:26.357267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_overall]\npredictions_as_answer_letters[:3]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:19:26.359566Z","iopub.execute_input":"2023-09-13T04:19:26.360167Z","iopub.status.idle":"2023-09-13T04:19:26.368199Z","shell.execute_reply.started":"2023-09-13T04:19:26.360134Z","shell.execute_reply":"2023-09-13T04:19:26.367185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]\npredictions_as_string[:3]","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:34.557463Z","iopub.status.idle":"2023-09-13T04:10:34.557934Z","shell.execute_reply.started":"2023-09-13T04:10:34.557683Z","shell.execute_reply":"2023-09-13T04:10:34.557706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)\n\npd.read_csv('submission.csv').head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T04:10:34.559724Z","iopub.status.idle":"2023-09-13T04:10:34.560205Z","shell.execute_reply.started":"2023-09-13T04:10:34.559964Z","shell.execute_reply":"2023-09-13T04:10:34.559985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, at least we were able to confirm that the openbook model (based on Ozturk's and Chris'), which differs in method from other models and has a high score, has the higher weight.\n\nNow it's your turn to blend. Let's add weights for your model. \n\nAlso, running notebooks, especially inference for openbook model, takes a long time, so it's a good idea to separate notebooks for calculating weights and for submitting them like Yirun Zhangs' base notebook.\n\nIt would also be important to change the evaluation dataset to something relevant to STEM. If the model weights are unnaturally high, suspect a leak. And make sure the evaluation dataset is not used for training.\n\n### Wishing you happy kaggling!","metadata":{}}]}